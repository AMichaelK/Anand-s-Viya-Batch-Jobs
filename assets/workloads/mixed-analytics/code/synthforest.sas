/**********************************************************************
 * Copyright (c) 2023 by SAS Institute Inc, Cary NC 27511  USA
 * Synthetic Data Random Forest Workload
 *
 * NAME:  synthforest.sas
 * DESCRIPTION: performance test for model developing algorithms known to use parallel
 * 				across multiple threads when available. Data generation part of program
 *				to avoid any dependencies.
 *
 * SETUP INSTRUCTIONS:
 *   Data for this test is generated by the test.  Obs can be set to dictate run-time/scale.
 *
 * SYSTEM REQUIREMENTS:  NA
 *
 * ANTICIPATED RUNTIME:  TBD
 * TEST CHARACTERIZATION:  
 *
 * SAS PRODUCTS INVOLVED:  Base SAS
 * SAS PROCEDURES INVOLVED: Data Step, PROC freq, stdize, sort, tree, surveyselect
							multi-thread leveraging with PROC HPCLUS, HPFOREST
 *
 * DATA SOURCE:  self-generated
 * DATA CHARACTERIZATION:  distribution-governed with random noise
 *
 * COMMENTS:
 * DISTRIBUTION STATUS:  Internal
 * CONTRIBUTED BY:  Joe Cabral
 * HISTORY:
 *   Date       Description                       Who
 *  09MAY23     Began workload development		  Joe Cabral
 **********************************************************************/

/**********************************************************************
 *Starting code for log review information                             
 **********************************************************************/
/**********************************************************************
 *Starting code for log review information                             
 **********************************************************************/

%macro stdout (command, debug=no);

  %local fileref fid rc;

  %let rc = %sysfunc (filename (fileref, &command, PIPE));

%if &debug=yes %then %put fileref=&fileref;

  %if &rc = 0 %then %do;

    %let fid = %sysfunc (fopen (&fileref, S));
    %if &fid ne 0 %then %do;

      %do %while(%sysfunc(fread(&fid)) = 0);

        %local line;
        %let rc = %qsysfunc(fget(&fid,line,200));

%if &debug=yes %then %put line=&line;

        &line

      %end;

      %let fid = %sysfunc (fclose (&fid));
    %end;
    %else %do;

      %put ERRROR: PIPE OPEN FAILED, %sysfunc(sysmsg());
      PIPE OPEN FAILED

    %end;

    %let rc = %sysfunc (filename (fileref));
  %end;
  %else %do;
    %put ERRROR: COMMAND PIPE SETUP FAILED, rc=&rc..;
    COMMAND PIPE SETUP FAILED
  %end;

%mend;

/**********************************************************************
 *Ending - code for log review information                            
 **********************************************************************/

/*******************************************************************************
 *                        PROGRAM SETUP
 * Use this section to alter macro variables, options, or other aspects of the
 * test.  No Edits to this Program are allowed past the Program Setup section!!
 *******************************************************************************/

%let mysysparm=%sysfunc(getoption(SYSPARM));
*%let suiteloc=%sysget(ASUITE);
%put &suiteloc;

* running in SAS Studio & not using a SYSPARM? Define suiteloc below;
%let suiteloc=synthforest;

libname in  "&suiteloc/input/";
libname out "&suiteloc/output/";

* choose number of rows to generate;
%let nrows=50000;

/* End of Data Setup Section */

/*******************************************************************************
 *                       END OF PROGRAM SETUP
 *******************************************************************************/

/* Do NOT edit below this line! */

options fmterr fullstimer source source2 mprint notes;

/******************************************************************************
 * INPUT DATA SET
 * CHARACTERISTICS:
 * 		self-generated - no external dependencies
 *		distribution governed
 *		~ 100 columns
 * 		configurable row count - default is 10M
 * 
 * PURPOSE: usage by classification procedure to segment data
 *			then by HP random forest procedure to predict classifications
 * 			
 *****************************************************************************/

data noise;
	* generate noise from normal distribution, amplitude 10;
	array err(100);
	* each row iterates nvars times;
	do i = 1 to &nrows;
		* row iterator;
		row = i;
		do j = 1 to 100;
			err(j) = rand("Uniform",-3,3);
		end;
		output;
	end;
run;

data dists;
	* generate variable values from several different distributions;
	array col(100);
	* each column will have a corresponding error column, which will be added to it later;
	do i = 1 to &nrows;
		* row iterator;
		row = i;
		* divide columns into sections, each governed by different types of distributions;
		do j = 1 to 10;
			* normal distributions with diff means & stdevs;
			col(j) = rand("Uniform") * j + 5*j; 
		end;
		do j = 11 to 20;
			* geometric distributions with diff probabilities;
			col(j) = rand("Geometric", j/100);
		end;
		do j = 21 to 30;
			* exponential distributions with different scales;
			col(j) = rand("Exponential", (2**(j-20)/10));
		end;
		do j = 31 to 40;
			* Poisson distributions with different means;
			* Yes, this is linked intuitively to exponential behavior so it's a tad repetitive;
			col(j) = rand("Poisson",(j-30)**2);
		end;
		do j = 41 to 50;
			* amplified binary & conditioned on the previous 10 Poisson columns;
			* this might make some variables less useful to the clustering and modeling later;
			if col(j-10) < (j-40)**2 then do;
				col(j) = 0;
			end;
			else do;
				col(j) = 8;
			end;
		end;
		do j = 51 to 60;
			* more conditioned variables to give some redundancy to classification;
			col(j) = rand("F",col(j-50),col(j-40));
		end;
		do j = 61 to 70;
			* binomial distributions, introducing dependency on row number;
			col(j) = rand("Binomial",exp(-i/&nrows),(j-60)*10);
		end;
		do j = 71 to 80;
			* negative binomial variables;
			col(j) = rand("NegBinomial",rand("Uniform"),ceil((j-70)/2));
		end;
		do j = 81 to 90;
			* discrete distribution;
			col(j) = rand("TABLE",0.5,(j-80)/20,(90-j)/20);
		end;
		do j = 91 to 100;
			* combo distribution, uniform & lognormal;
			col(j) = rand("Uniform",j-90,j-89) + rand("Lognormal",(100-j)/5);
		end;
		* output 100 column result;
		output;
	end;
run;

* TODO: we can definitely create and combine the two tables in ONE data step;
data agg;
	* combine two tables to generate final table for clustering;
	merge work.dists work.noise;
	by row;
	keep val1-val100 row;
	* array definition to create final column names;
	array val(100);
	array col(100);
	array err(100);
	* each final value is the sum of the dist and the noise;
	do i = 1 to 100;
		val(i) = col(i) + err(i);
	end;
run;

* normalize the variables val1-val100;
proc stdize data=work.agg out=norm;
	var val1-val100;
run;

* clustering algorithm with multi-threaded processing;
proc HPCLUS data=work.norm;
	input val1-val100;
	id row val1-val100;
	score out=clustree;
run;

* with the cluster labels merged with the data, we can do a train-test split;
* SRS method might not be ideal since clusters might be disproportionately represented;
proc surveyselect data=work.clustree rate=0.7 out=labeled_select outall method=srs;
run;

proc sort data=labeled_select out=labeled_sorted;
	by _CLUSTER_ID_;
run;

proc freq data=labeled_sorted;
	table _CLUSTER_ID_;	
run;

data train_data(drop=Selected) test_data(drop=Selected);
	* reorder columns and remove the "Selected" column;
	set labeled_select;
	rename _CLUSTER_ID_ = cluster _DISTANCE_ = distance;
	if selected = 1 then output train_data;
	else output test_data;
run;

* now we can create a model on the training data;
* PROC HPFOREST runs on all available cores and concurrent threads;
filename outmodel "C:\Temp\HPForestModel";
PROC HPFOREST data=work.train_data;
	input val1-val100;
	id row;
	target CLUSTER/level=nominal;
	score out=train_score;
	ods output FitStatistics=fitstats;
	* by saving a binary file, we have a means of scoring test data;
	save file = outmodel;
run;

* make predictions on the testing data;
proc HP4SCORE data=test_data;
	score file=outmodel out=test_scores;
run;

* sort data by cluster for easy misclassification analysis / display;
proc sort data=work.test_scores out=test_scores;
	by cluster;
run;

* find misclassified records;
data test_scores;
	set test_scores;
	if input(I_cluster,best.) eq cluster then misclass = 0;
	else misclass = 1;
run;

* calculate misclassification rate;
title 'Overall Misclassification Rate';
proc means data=test_scores mean;
	var misclass;
run;

title 'Misclassification Rrates Across Different Clusters';
proc means data=test_scores mean;
	var misclass;
	class cluster;
run;